{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting and saving requirements"
      ],
      "metadata": {
        "id": "rTj660p4N8lA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a notebook that shows how to extract requirements from a test dataset using a specific model. We will be extracting them eight times, once for each model trained for the Cross-Validation method. "
      ],
      "metadata": {
        "id": "yuB-vyumOH80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "UjVjtDUrEX1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connecting to google drive to save the extracted requirements there. "
      ],
      "metadata": {
        "id": "obl0GPFbPcLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import shutil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOFvrUvGHN6j",
        "outputId": "f17c57f3-d789-4481-b513-f5e6f7afcf3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cloning a RE-BERT repository."
      ],
      "metadata": {
        "id": "VHn7z1A9Eqy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/BruNamie/RE-BERT\n",
        "!mv RE-BERT/* ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkIAaXvvEmeD",
        "outputId": "0a21b674-982d-46be-89ce-05c242baebc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RE-BERT'...\n",
            "remote: Enumerating objects: 197, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 197 (delta 64), reused 81 (delta 42), pack-reused 86\u001b[K\n",
            "Receiving objects: 100% (197/197), 3.02 MiB | 20.62 MiB/s, done.\n",
            "Resolving deltas: 100% (91/91), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2kU778bieDi"
      },
      "source": [
        "Installing dependencies."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO88tArXEoUd",
        "outputId": "98193803-02ad-4180-9b29-752babeb697e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.12.1+cu113)\n",
            "Collecting transformers==2.3.0\n",
            "  Downloading transformers-2.3.0-py3-none-any.whl (447 kB)\n",
            "\u001b[K     |████████████████████████████████| 447 kB 34.0 MB/s \n",
            "\u001b[?25hCollecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0->-r requirements.txt (line 3)) (4.64.1)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.4-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 73.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0->-r requirements.txt (line 3)) (2022.6.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 61.6 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 59.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->-r requirements.txt (line 2)) (4.1.1)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.9 MB/s \n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.4\n",
            "  Downloading botocore-1.29.4-py3-none-any.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 65.0 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 75.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.30.0,>=1.29.4->boto3->transformers==2.3.0->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.4->boto3->transformers==2.3.0->-r requirements.txt (line 3)) (1.15.0)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 72.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 3)) (2022.9.24)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0->-r requirements.txt (line 3)) (1.2.0)\n",
            "Building wheels for collected packages: sklearn, sacremoses\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=54fdd4dbd00a2565b8e164d6759cbf50b9484a987392919ce3e15c074a664383\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/56/cc/4a8bf86613aafd5b7f1b310477667c1fca5c51c3ae4124a003\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=1ad374a0cacacbe06dd1fbf47a7df225a5e0618d4cf8fd52db00714de01655dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sklearn sacremoses\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, transformers, sklearn\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.26.4 botocore-1.29.4 jmespath-1.0.1 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.97 sklearn-0.0.post1 transformers-2.3.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv0yuEUJyMyQ"
      },
      "source": [
        "Downloading pre-trained RE-BERT models. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwIZ6x1ED3BC",
        "outputId": "d45ccf01-f0dc-40a9-df34-71607704a936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-d9wqii02ehPF83zosSYT9eVHK5e4t6d\n",
            "To: /content/RE_BERT_CV0_iob_epoch_1.model\n",
            "100% 455M/455M [00:02<00:00, 183MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-bqjlBjYgud4WC7fEUugZuhV4dRrTZ7Y\n",
            "To: /content/RE_BERT_CV1_iob_epoch_1.model\n",
            "100% 455M/455M [00:01<00:00, 228MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-ZGPqAhG2wSTxVX7ylPi6Moqt4cZ04JZ\n",
            "To: /content/RE_BERT_CV2_iob_epoch_1.model\n",
            "100% 455M/455M [00:01<00:00, 283MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-Ycu9zmCOHFEdMyk3JKuc9Cc70GmMzWS\n",
            "To: /content/RE_BERT_CV3_iob_epoch_1.model\n",
            "100% 455M/455M [00:01<00:00, 235MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-Uwzexg8SEjLrGXRSU4TvPE3SL0QSwZw\n",
            "To: /content/RE_BERT_CV4_iob_epoch_1.model\n",
            "100% 455M/455M [00:01<00:00, 276MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-TAAIJpdKlr8kINyJc_qh7xA6v0PaK9d\n",
            "To: /content/RE_BERT_CV5_iob_epoch_1.model\n",
            "100% 455M/455M [00:01<00:00, 300MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-Lvclttw8LrMmEq2lypPXtzzoEVH6YTa\n",
            "To: /content/RE_BERT_CV6_iob_epoch_1.model\n",
            "100% 455M/455M [00:01<00:00, 287MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-FYCx4SVumELe60tQqMICsDePPo8c-RP\n",
            "To: /content/RE_BERT_CV7_iob_epoch_1.model\n",
            "100% 455M/455M [00:01<00:00, 258MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=1-d9wqii02ehPF83zosSYT9eVHK5e4t6d\n",
        "!gdown https://drive.google.com/uc?id=1-bqjlBjYgud4WC7fEUugZuhV4dRrTZ7Y\n",
        "!gdown https://drive.google.com/uc?id=1-ZGPqAhG2wSTxVX7ylPi6Moqt4cZ04JZ\n",
        "!gdown https://drive.google.com/uc?id=1-Ycu9zmCOHFEdMyk3JKuc9Cc70GmMzWS\n",
        "!gdown https://drive.google.com/uc?id=1-Uwzexg8SEjLrGXRSU4TvPE3SL0QSwZw\n",
        "!gdown https://drive.google.com/uc?id=1-TAAIJpdKlr8kINyJc_qh7xA6v0PaK9d\n",
        "!gdown https://drive.google.com/uc?id=1-Lvclttw8LrMmEq2lypPXtzzoEVH6YTa\n",
        "!gdown https://drive.google.com/uc?id=1-FYCx4SVumELe60tQqMICsDePPo8c-RP"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_models = ['RE_BERT_CV0_iob_epoch_1.model', 'RE_BERT_CV1_iob_epoch_1.model', 'RE_BERT_CV2_iob_epoch_1.model', 'RE_BERT_CV3_iob_epoch_1.model',\n",
        "                      'RE_BERT_CV4_iob_epoch_1.model', 'RE_BERT_CV5_iob_epoch_1.model', 'RE_BERT_CV6_iob_epoch_1.model', 'RE_BERT_CV7_iob_epoch_1.model']"
      ],
      "metadata": {
        "id": "CBioxZG7GJ1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting software requirements"
      ],
      "metadata": {
        "id": "UlVjKr21FLam"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to note that the codes presented below are repeated for each iteration. The process to extract requirements was carried out in this way due to limitations of Google Colab, the platform used for this. "
      ],
      "metadata": {
        "id": "6J_J8h8MQrwh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing model #1"
      ],
      "metadata": {
        "id": "3mDUQuY3FC-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CV_number = '0'\n",
        "model_chosen = pre_trained_models[int(CV_number)]"
      ],
      "metadata": {
        "id": "9HdC7Z5iFEsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python extract.py --test_file test_data_eBay.txt --classifier_model_file RE_BERT_CV{CV_number}_iob_epoch_1.model --output_file CV_{CV_number}_extracted_reqs.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3VSP-89FILK",
        "outputId": "a4507b13-87a5-4743-ac7f-7b38b2ee80cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "loading model RE_BERT ...\n",
            "Test Size: 294\n",
            "Extract software requirements candidates:   0% 0/294 [00:00<?, ?it/s]extract.py:72: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "Extract software requirements candidates: 100% 294/294 [01:30<00:00,  3.25it/s]\n",
            "Extracted software requirements --> CV_0_extracted_reqs.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy(\"CV_\"+CV_number+\"_extracted_reqs.txt\",\"/content/drive/MyDrive/Colab Notebooks/Requirements_extracted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZSihT-FrGkGi",
        "outputId": "a1fe9031-c6db-4a61-92aa-1bd70f26929c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/Requirements_extracted/CV_0_extracted_reqs.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing model #2"
      ],
      "metadata": {
        "id": "kArHEyzaHUA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CV_number = '1'\n",
        "model_chosen = pre_trained_models[int(CV_number)]"
      ],
      "metadata": {
        "id": "F4IHjDaaHVZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python extract.py --test_file test_data_Evernote.txt --classifier_model_file RE_BERT_CV{CV_number}_iob_epoch_1.model --output_file CV_{CV_number}_extracted_reqs.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BINAevk6HbXs",
        "outputId": "76f95d0f-15fa-4039-e5c6-29b4d3eb9cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "loading model RE_BERT ...\n",
            "Test Size: 367\n",
            "Extract software requirements candidates:   0% 0/367 [00:00<?, ?it/s]extract.py:72: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "Extract software requirements candidates: 100% 367/367 [02:20<00:00,  2.61it/s]\n",
            "Extracted software requirements --> CV_1_extracted_reqs.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy(\"CV_\"+CV_number+\"_extracted_reqs.txt\",\"/content/drive/MyDrive/Colab Notebooks/Requirements_extracted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_ZMLhZMbHc9J",
        "outputId": "457809fb-6b83-4870-f873-acf96e173060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/Requirements_extracted/CV_1_extracted_reqs.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing model #3"
      ],
      "metadata": {
        "id": "fSQmL3fMHefk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CV_number = '2'\n",
        "model_chosen = pre_trained_models[int(CV_number)]"
      ],
      "metadata": {
        "id": "HZQAo_h0IMn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python extract.py --test_file test_data_Facebook.txt --classifier_model_file RE_BERT_CV{CV_number}_iob_epoch_1.model --output_file CV_{CV_number}_extracted_reqs.txt"
      ],
      "metadata": {
        "id": "Ub0MlHiiIOq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3411d4d-0bea-4102-fb78-541eda4503d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "loading model RE_BERT ...\n",
            "Test Size: 327\n",
            "Extract software requirements candidates:   0% 0/327 [00:00<?, ?it/s]extract.py:72: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "Extract software requirements candidates: 100% 327/327 [01:44<00:00,  3.12it/s]\n",
            "Extracted software requirements --> CV_2_extracted_reqs.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy(\"CV_\"+CV_number+\"_extracted_reqs.txt\",\"/content/drive/MyDrive/Colab Notebooks/Requirements_extracted\")"
      ],
      "metadata": {
        "id": "ByqdG1gzIP-T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "94beed8e-e57b-4b55-fafa-cbae82409bc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/Requirements_extracted/CV_2_extracted_reqs.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing model #4"
      ],
      "metadata": {
        "id": "LNxqEtrbHlTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CV_number = '3'\n",
        "model_chosen = pre_trained_models[int(CV_number)]"
      ],
      "metadata": {
        "id": "qJJWGPDXISlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python extract.py --test_file test_data_Netflix.txt --classifier_model_file RE_BERT_CV{CV_number}_iob_epoch_1.model --output_file CV_{CV_number}_extracted_reqs.txt"
      ],
      "metadata": {
        "id": "HlOmBYA0IUl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b4e4311-b37d-454b-dc99-77c9e4b8fc7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "loading model RE_BERT ...\n",
            "Test Size: 341\n",
            "Extract software requirements candidates:   0% 0/341 [00:00<?, ?it/s]extract.py:72: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "Extract software requirements candidates: 100% 341/341 [02:03<00:00,  2.77it/s]\n",
            "Extracted software requirements --> CV_3_extracted_reqs.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy(\"CV_\"+CV_number+\"_extracted_reqs.txt\",\"/content/drive/MyDrive/Colab Notebooks/Requirements_extracted\")"
      ],
      "metadata": {
        "id": "84790U8ZIWGs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f752a841-ed7c-4054-aaad-dcb30fb961a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/Requirements_extracted/CV_3_extracted_reqs.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing model #5"
      ],
      "metadata": {
        "id": "D6VBiL7sH5d-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CV_number = '4'\n",
        "model_chosen = pre_trained_models[int(CV_number)]"
      ],
      "metadata": {
        "id": "ZTEr5menI_6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python extract.py --test_file test_data_PhotoEditor.txt --classifier_model_file RE_BERT_CV{CV_number}_iob_epoch_1.model --output_file CV_{CV_number}_extracted_reqs.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWPPBrG4JBW_",
        "outputId": "7307486e-9240-4805-82ea-c73d665f9e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "loading model RE_BERT ...\n",
            "Test Size: 154\n",
            "Extract software requirements candidates:   0% 0/154 [00:00<?, ?it/s]extract.py:72: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "Extract software requirements candidates: 100% 154/154 [00:35<00:00,  4.40it/s]\n",
            "Extracted software requirements --> CV_4_extracted_reqs.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy(\"CV_\"+CV_number+\"_extracted_reqs.txt\",\"/content/drive/MyDrive/Colab Notebooks/Requirements_extracted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "788JmQW7JCGN",
        "outputId": "6f92806a-829f-4703-acef-24f45ba5f6da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/Requirements_extracted/CV_4_extracted_reqs.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing model #6"
      ],
      "metadata": {
        "id": "LSotpsU5JCtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CV_number = '5'\n",
        "model_chosen = pre_trained_models[int(CV_number)]"
      ],
      "metadata": {
        "id": "Yn-V_6XwJGBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python extract.py --test_file test_data_Spotify.txt --classifier_model_file RE_BERT_CV{CV_number}_iob_epoch_1.model --output_file CV_{CV_number}_extracted_reqs.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chLPgeH8JFPm",
        "outputId": "af24268c-74e6-4a22-8029-bc290d56f415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "loading model RE_BERT ...\n",
            "Test Size: 227\n",
            "Extract software requirements candidates:   0% 0/227 [00:00<?, ?it/s]extract.py:72: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "Extract software requirements candidates: 100% 227/227 [01:05<00:00,  3.44it/s]\n",
            "Extracted software requirements --> CV_5_extracted_reqs.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy(\"CV_\"+CV_number+\"_extracted_reqs.txt\",\"/content/drive/MyDrive/Colab Notebooks/Requirements_extracted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8ahogpW0JD3f",
        "outputId": "be302ce3-68ce-446d-e3e3-f44215b2513d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/Requirements_extracted/CV_5_extracted_reqs.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing model #7"
      ],
      "metadata": {
        "id": "C4RBpa-zJI9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CV_number = '6'\n",
        "model_chosen = pre_trained_models[int(CV_number)]"
      ],
      "metadata": {
        "id": "sqVPcCdBJJ_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python extract.py --test_file test_data_Twitter.txt --classifier_model_file RE_BERT_CV{CV_number}_iob_epoch_1.model --output_file CV_{CV_number}_extracted_reqs.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-7Y_Pp9JMBc",
        "outputId": "4f800b0c-4723-4b86-84ae-e38fc667f6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "loading model RE_BERT ...\n",
            "Test Size: 183\n",
            "Extract software requirements candidates:   0% 0/183 [00:00<?, ?it/s]extract.py:72: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "Extract software requirements candidates: 100% 183/183 [00:42<00:00,  4.27it/s]\n",
            "Extracted software requirements --> CV_6_extracted_reqs.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy(\"CV_\"+CV_number+\"_extracted_reqs.txt\",\"/content/drive/MyDrive/Colab Notebooks/Requirements_extracted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "njrWxQ2XJMq5",
        "outputId": "c9f733c3-3c2b-4aa5-9caf-b998a86d0de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/Requirements_extracted/CV_6_extracted_reqs.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing model #8"
      ],
      "metadata": {
        "id": "PqGkRvLeJNix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CV_number = '7'\n",
        "model_chosen = pre_trained_models[int(CV_number)]"
      ],
      "metadata": {
        "id": "3sqiMx72N5pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python extract.py --test_file test_data_WhatsApp.txt --classifier_model_file RE_BERT_CV{CV_number}_iob_epoch_1.model --output_file CV_{CV_number}_extracted_reqs.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfJprYkIJZFH",
        "outputId": "70f331e2-5eb5-44c7-aece-b1462b105f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "loading model RE_BERT ...\n",
            "Test Size: 169\n",
            "Extract software requirements candidates:   0% 0/169 [00:00<?, ?it/s]extract.py:72: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "Extract software requirements candidates: 100% 169/169 [00:39<00:00,  4.26it/s]\n",
            "Extracted software requirements --> CV_7_extracted_reqs.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy(\"CV_\"+CV_number+\"_extracted_reqs.txt\",\"/content/drive/MyDrive/Colab Notebooks/Requirements_extracted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oxhCtY1SJaDv",
        "outputId": "8825f08f-f592-4050-d242-72c530648ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/Requirements_extracted/CV_7_extracted_reqs.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}